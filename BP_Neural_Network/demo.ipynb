{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='data/', train=True, download=True, transform=None)\n",
    "test_dataset = datasets.MNIST(root='data/', train=False, download=True, transform=None)\n",
    "\n",
    "# Extract images and labels\n",
    "train_imgs = train_dataset.data.numpy()\n",
    "train_labels = train_dataset.targets.numpy()\n",
    "\n",
    "test_imgs = test_dataset.data.numpy()\n",
    "test_labels = test_dataset.targets.numpy()\n",
    "\n",
    "# Normalize pixel values\n",
    "train_imgs = train_imgs / 255.0\n",
    "test_imgs = test_imgs / 255.0\n",
    "\n",
    "# Flatten images\n",
    "train_imgs = train_imgs.reshape(train_imgs.shape[0], -1)\n",
    "test_imgs = test_imgs.reshape(test_imgs.shape[0], -1)\n",
    "\n",
    "# One-hot encode labels\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "train_labels = enc.fit_transform(train_labels.reshape(-1, 1))\n",
    "test_labels = enc.transform(test_labels.reshape(-1, 1))\n",
    "\n",
    "# Split training set into train and validation sets\n",
    "train_imgs, val_imgs, train_labels, val_labels = train_test_split(train_imgs, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define neural network architecture\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.W1 = np.random.randn(input_size, hidden_size)\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size)\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self.softmax(self.z2)\n",
    "        return self.a2\n",
    "    \n",
    "    def backward(self, X, y, learning_rate):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        delta2 = self.a2 - y\n",
    "        dW2 = (1 / m) * np.dot(self.a1.T, delta2)\n",
    "        db2 = (1 / m) * np.sum(delta2, axis=0, keepdims=True)\n",
    "        \n",
    "        delta1 = np.dot(delta2, self.W2.T) * self.sigmoid_derivative(self.a1)\n",
    "        dW1 = (1 / m) * np.dot(X.T, delta1)\n",
    "        db1 = (1 / m) * np.sum(delta1, axis=0)\n",
    "        \n",
    "        self.W2 -= learning_rate * dW2\n",
    "        self.b2 -= learning_rate * db2\n",
    "        self.W1 -= learning_rate * dW1\n",
    "        self.b1 -= learning_rate * db1\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        exp_scores = np.exp(x)\n",
    "        return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "# Initialize neural network\n",
    "input_size = train_imgs.shape[1]\n",
    "hidden_size = 64\n",
    "output_size = 10\n",
    "learning_rate = 0.1\n",
    "num_epochs = 100\n",
    "\n",
    "model = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "\n",
    "# Training loop\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model.forward(train_imgs)\n",
    "    \n",
    "    # Backward pass\n",
    "    model.backward(train_imgs, train_labels, learning_rate)\n",
    "    \n",
    "    # Compute training accuracy\n",
    "    train_preds = np.argmax(outputs, axis=1)\n",
    "    train_acc = np.mean(train_preds == np.argmax(train_labels, axis=1))\n",
    "    train_accs.append(train_acc)\n",
    "    \n",
    "    # Compute validation accuracy\n",
    "    val_outputs = model.forward(val_imgs)\n",
    "    val_preds = np.argmax(val_outputs, axis=1)\n",
    "    val_acc = np.mean(val_preds == np.argmax(val_labels, axis=1))\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "epochs = range(1, num_epochs+1)\n",
    "plt.plot(epochs, train_accs, label='Train Accuracy')\n",
    "plt.plot(epochs, val_accs, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Test the model\n",
    "test_outputs = model.forward(test_imgs)\n",
    "test_preds = np.argmax(test_outputs, axis=1)\n",
    "test_acc = np.mean(test_preds == np.argmax(test_labels, axis=1))\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(np.argmax(test_labels, axis=1), test_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_dataset = datasets.MNIST(root='data/',train=True,download=True,transform=None)\n",
    "test_dataset = datasets.MNIST(root='data/',train=False,download=True,transform=None)\n",
    "\n",
    "train_imgs = train_dataset.data.numpy()/255\n",
    "train_imgs = train_imgs.reshape(train_imgs.shape[0],28*28)\n",
    "train_labels = train_dataset.targets.numpy()\n",
    "\n",
    "test_imgs = test_dataset.data.numpy()/255\n",
    "test_imgs = test_imgs.reshape(test_imgs.shape[0],28*28)\n",
    "test_labels = test_dataset.targets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function for reading idx file format\n",
    "def read_idx(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "\n",
    "# Preprocessing functions\n",
    "def normalize_images(images):\n",
    "    return images / 255\n",
    "\n",
    "def one_hot_labels(labels):\n",
    "    one_hot = np.zeros((labels.size, labels.max() + 1))\n",
    "    one_hot[np.arange(labels.size), labels] = 1\n",
    "    return one_hot\n",
    "\n",
    "# Activation functions and their derivatives\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# Parameter initialization\n",
    "def initialize_parameters(n_inputs, n_hidden, n_outputs):\n",
    "    W1 = np.random.randn(n_hidden, n_inputs)\n",
    "    b1 = np.zeros((n_hidden, 1))\n",
    "    W2 = np.random.randn(n_outputs, n_hidden)\n",
    "    b2 = np.zeros((n_outputs, 1))\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# Forward propagation\n",
    "def forward_propagation(X, W1, b1, W2, b2):\n",
    "    X = X.reshape(-1, 28*28)\n",
    "    Z1 = np.dot(W1, X.T) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "# Backward propagation\n",
    "def backward_propagation(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
    "    X = X.reshape(-1, 28*28)\n",
    "    m_batch = X.shape[0]\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1./m_batch) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1./m_batch) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    dZ1 = dA1 * sigmoid_derivative(Z1)\n",
    "    dW1 = (1./m_batch) * np.dot(dZ1, X)\n",
    "    db1 = (1./m_batch) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "# Parameter update\n",
    "def update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# Neural network training\n",
    "def train(X, Y, n_hidden=64, learning_rate=0.01, n_epochs=10, batch_size=64):\n",
    "    n_inputs = X.shape[1]*X.shape[2]  # 28*28\n",
    "    n_outputs = Y.shape[1]  # 10\n",
    "    W1, b1, W2, b2 = initialize_parameters(n_inputs, n_hidden, n_outputs)\n",
    "    for epoch in range(n_epochs):\n",
    "        permutation = np.random.permutation(X.shape[0])\n",
    "        X_shuffled = X[permutation]\n",
    "        Y_shuffled = Y[permutation]\n",
    "        for i in range(0, X.shape[0], batch_size):\n",
    "            X_batch = X_shuffled[i:i+batch_size]\n",
    "            Y_batch = Y_shuffled[i:i+batch_size].T\n",
    "            Z1, A1, Z2, A2 = forward_propagation(X_batch, W1, b1, W2, b2)\n",
    "            dW1, db1, dW2, db2 = backward_propagation(Z1, A1, Z2, A2, W1, W2, X_batch, Y_batch)\n",
    "            W1, b1, W2, b2 = update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# Predictions\n",
    "def predict(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward_propagation(X, W1, b1, W2, b2)\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "# Load the data\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
